{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Reshape\n",
    "import sys\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar datos de entrenamiento\n",
    "training_set = sys.argv[0] = \"/home/arthur1/Documentos/GitHub/Prueba/Datos/Salida/Datos_entrenamiento_TCGA_matriz.npy\" ### \"Input data npy file\" \n",
    "x_sample = np.load ( training_set )\n",
    "x_train = x_sample.reshape ((x_sample.shape[0], 100, 100,1)) # No. de muestras, Longitud, Ancho, No. de filtros\n",
    "# Cargar etiquetas de los datos de entrenamiento\n",
    "training_label = sys.argv[0] = \"/home/arthur1/Documentos/GitHub/Prueba/Datos/Salida/Datos_entrenamiento_TCGA_etiquetas.npy\" ### \"Input label npy file\" \n",
    "y_label = np.load ( training_label )\n",
    "y_train = to_categorical(y_label, num_classes=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de validacion\n",
    "testing_set = sys.argv[0] = \"/home/arthur1/Documentos/GitHub/Prueba/Datos/Salida/Datos_validacion_TCGA_matriz.npy\"\n",
    "test_sample = np.load ( testing_set )\n",
    "x_test = test_sample.reshape ( (test_sample.shape[0], 100, 100, 1) ) # no. of samples, x pixels, y pixels, no. of files\n",
    "\n",
    "# Carga de etiquetas de datos de validacion\n",
    "testing_label = sys.argv[0] = \"/home/arthur1/Documentos/GitHub/Prueba/Datos/Salida/Datos_validacion_TCGA_etiquetas.npy\"\n",
    "test_label = np.load ( testing_label )\n",
    "test_label_compare = test_label\n",
    "y_test = to_categorical (test_label,num_classes=12 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_rnn(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Construye una RNN para clasificación.\n",
    "\n",
    "    Args:\n",
    "        input_shape: Tupla que define la forma de los datos de entrada (largo, ancho, canales).\n",
    "        num_classes: Número de clases para clasificación.\n",
    "\n",
    "    Returns:\n",
    "        Modelo Keras compilado.\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Aplanar las dimensiones espaciales (altura y anchura)\n",
    "    model.add(layers.Reshape((input_shape[0], input_shape[1] * input_shape[2]), input_shape=input_shape))\n",
    "\n",
    "    # Capa RNN\n",
    "    model.add(layers.SimpleRNN(128, input_shape=input_shape, return_sequences=True))  # Puedes ajustar las unidades según sea necesario\n",
    "    model.add(layers.SimpleRNN(64, return_sequences=False))\n",
    "\n",
    "    # Capas densas para la clasificación\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Dropout para regularización\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))  # Capa de salida con activación softmax\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(optimizer='adam',  # Puedes probar otros optimizadores\n",
    "                  loss='categorical_crossentropy',  # Función de pérdida para clasificación multiclase\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (100, 100, 1)  # Largo, ancho, canales\n",
    "num_classes = 12\n",
    "num_samples = 1000\n",
    "\n",
    "#rnn_model.summary()  # Imprime un resumen del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
